{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcgJHLMLqWjK",
        "outputId": "e983aaf2-da47-4b51-a9e1-1cbf732dbb66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hpF77OZBxqKc"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "\n",
        "# Load Count Vectorizer data\n",
        "X_train_cv = joblib.load('/content/drive/MyDrive/X_train_cv.joblib')\n",
        "X_val_cv = joblib.load('/content/drive/MyDrive/X_val_cv.joblib')\n",
        "y_train_cv = joblib.load('/content/drive/MyDrive/y_train_cv.joblib')\n",
        "y_val_cv = joblib.load('/content/drive/MyDrive/y_val_cv.joblib')\n",
        "X_test_cv = joblib.load('/content/drive/MyDrive/X_test_cv.joblib')\n",
        "cv = joblib.load('/content/drive/MyDrive/count_vectorizer.joblib')\n",
        "\n",
        "# Load TFIDF Vectorizer data\n",
        "X_train_tfidf = joblib.load('/content/drive/MyDrive/X_train_tfidf.joblib')\n",
        "X_val_tfidf = joblib.load('/content/drive/MyDrive/X_val_tfidf.joblib')\n",
        "y_train_tfidf = joblib.load('/content/drive/MyDrive/y_train_tfidf.joblib')\n",
        "y_val_tfidf = joblib.load('/content/drive/MyDrive/y_val_tfidf.joblib')\n",
        "X_test_tfidf = joblib.load('/content/drive/MyDrive/X_test_tfidf.joblib')\n",
        "tfidf = joblib.load('/content/drive/MyDrive/tfidf_vectorizer.joblib')\n",
        "\n",
        "# Load Word2Vec data\n",
        "X_train_w2v = joblib.load('/content/drive/MyDrive/X_train_w2v.joblib')\n",
        "X_val_w2v = joblib.load('/content/drive/MyDrive/X_val_w2v.joblib')\n",
        "y_train_w2v = joblib.load('/content/drive/MyDrive/y_train_w2v.joblib')\n",
        "y_val_w2v = joblib.load('/content/drive/MyDrive/y_val_w2v.joblib')\n",
        "X_test_w2v = joblib.load('/content/drive/MyDrive/X_test_w2v.joblib')\n",
        "w2v = joblib.load('/content/drive/MyDrive/word2vec_model.joblib')\n",
        "\n",
        "# Load y_test\n",
        "y_test = joblib.load('/content/drive/MyDrive/y_test.joblib')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ls-b8eh4CQ4k"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import ParameterGrid\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from tqdm import tqdm\n",
        "import joblib\n",
        "\n",
        "# Define the hyperparameter grid for XGBoost\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.01, 0.1],\n",
        "}\n",
        "\n",
        "# Function to run hypertuning for each vectorizer and return the best XGBoost model\n",
        "def tune_and_run_xgb_model(X_train, y_train, X_val, y_val, X_test, vectorizer_name):\n",
        "    param_combinations = list(ParameterGrid(param_grid))  # Get all parameter combinations\n",
        "    best_score = 0\n",
        "    best_params = None\n",
        "    best_xgb = None\n",
        "\n",
        "    # Progress bar using tqdm to track tuning process\n",
        "    for params in tqdm(param_combinations, desc=f\"Tuning XGBoost for {vectorizer_name}\", unit=\"combination\"):\n",
        "        # Initialize XGBoost with current hyperparameters\n",
        "        xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42, **params)\n",
        "\n",
        "        # Fit the XGBoost model\n",
        "        xgb.fit(X_train, y_train)\n",
        "\n",
        "        # Make predictions on validation data\n",
        "        y_pred_val = xgb.predict(X_val)\n",
        "\n",
        "        # Evaluate the model\n",
        "        accuracy = accuracy_score(y_val, y_pred_val)\n",
        "\n",
        "        # Keep track of the best model based on validation accuracy\n",
        "        if accuracy > best_score:\n",
        "            best_score = accuracy\n",
        "            best_params = params\n",
        "            best_xgb = xgb\n",
        "\n",
        "    # Print the best results for the current vectorizer\n",
        "    print(f\"\\nBest model for {vectorizer_name}:\")\n",
        "    print(f\"Best Validation Accuracy: {best_score * 100:.2f}%\")\n",
        "    print(f\"Best Hyperparameters: {best_params}\")\n",
        "\n",
        "    # Now use the best model to predict on the test data\n",
        "    y_pred_test = best_xgb.predict(X_test)\n",
        "\n",
        "    # Save the best model's predictions for the test set\n",
        "\n",
        "    return best_xgb, best_score, best_params, y_pred_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGmuly0_Co1a",
        "outputId": "8d03927c-7e03-4cc5-eff5-8f164288f840"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTuning XGBoost for Count_Vectorizer:   0%|          | 0/18 [00:00<?, ?combination/s]/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [23:03:51] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Tuning XGBoost for Count_Vectorizer:   6%|▌         | 1/18 [00:10<02:58, 10.51s/combination]/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [23:04:02] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Tuning XGBoost for Count_Vectorizer:  11%|█         | 2/18 [00:58<08:41, 32.62s/combination]/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [23:04:50] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Tuning XGBoost for Count_Vectorizer:  17%|█▋        | 3/18 [01:31<08:09, 32.66s/combination]/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [23:05:23] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Tuning XGBoost for Count_Vectorizer:  22%|██▏       | 4/18 [01:56<06:54, 29.63s/combination]/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [23:05:48] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Tuning XGBoost for Count_Vectorizer:  28%|██▊       | 5/18 [02:37<07:21, 33.95s/combination]/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [23:06:29] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Tuning XGBoost for Count_Vectorizer:  33%|███▎      | 6/18 [03:38<08:35, 42.98s/combination]/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [23:07:30] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Tuning XGBoost for Count_Vectorizer:  39%|███▉      | 7/18 [04:21<07:52, 42.91s/combination]/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [23:08:12] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Tuning XGBoost for Count_Vectorizer:  44%|████▍     | 8/18 [05:43<09:13, 55.37s/combination]/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [23:09:34] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Tuning XGBoost for Count_Vectorizer:  50%|█████     | 9/18 [07:42<11:16, 75.19s/combination]/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [23:11:33] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Tuning XGBoost for Count_Vectorizer:  56%|█████▌    | 10/18 [07:52<07:20, 55.09s/combination]/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [23:11:43] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Tuning XGBoost for Count_Vectorizer:  61%|██████    | 11/18 [08:08<05:03, 43.32s/combination]/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [23:12:00] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Tuning XGBoost for Count_Vectorizer:  67%|██████▋   | 12/18 [08:34<03:48, 38.10s/combination]/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [23:12:26] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Tuning XGBoost for Count_Vectorizer:  72%|███████▏  | 13/18 [08:55<02:44, 32.81s/combination]/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [23:12:47] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Tuning XGBoost for Count_Vectorizer:  78%|███████▊  | 14/18 [09:32<02:16, 34.08s/combination]/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [23:13:24] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Tuning XGBoost for Count_Vectorizer:  83%|████████▎ | 15/18 [10:24<01:58, 39.36s/combination]/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [23:14:15] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Tuning XGBoost for Count_Vectorizer:  89%|████████▉ | 16/18 [10:56<01:14, 37.28s/combination]/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [23:14:48] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Tuning XGBoost for Count_Vectorizer:  94%|█████████▍| 17/18 [11:58<00:44, 44.60s/combination]/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [23:15:49] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Tuning XGBoost for Count_Vectorizer: 100%|██████████| 18/18 [13:26<00:00, 44.80s/combination]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best model for Count_Vectorizer:\n",
            "Best Validation Accuracy: 65.08%\n",
            "Best Hyperparameters: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 300}\n",
            "Best KNN model for Count Vectorizer: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 300}, Validation Accuracy: 65.08%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Run the hypertuning process for Count Vectorizer\n",
        "best_xg_cv, best_score_cv, best_params_cv, y_pred_cv = tune_and_run_xgb_model(\n",
        "    X_train_cv, y_train_cv, X_val_cv, y_val_cv, X_test_cv, \"Count_Vectorizer\"\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Print out the best results for each model\n",
        "print(f\"Best KNN model for Count Vectorizer: {best_params_cv}, Validation Accuracy: {best_score_cv * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Assuming y_test is your true test labels and y_pred is your predicted test labels\n",
        "# Replace `y_test` with your actual test labels variable\n",
        "\n",
        "# Example: Test Accuracy and Classification Report for Count Vectorizer\n",
        "print(\"\\n--- Count Vectorizer Test Set Evaluation ---\")\n",
        "accuracy_cv = accuracy_score(y_test, y_pred_cv)\n",
        "report_cv = classification_report(y_test, y_pred_cv)\n",
        "\n",
        "print(f\"Test Accuracy for Count Vectorizer: {accuracy_cv * 100:.2f}%\")\n",
        "print(\"Classification Report:\")\n",
        "print(report_cv)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWuZ5_n2He1B",
        "outputId": "d729b05f-eac6-40af-94fd-3fc0721b5887"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Count Vectorizer Test Set Evaluation ---\n",
            "Test Accuracy for Count Vectorizer: 72.90%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.56      0.66       172\n",
            "           1       0.63      0.87      0.73       266\n",
            "           2       0.80      0.65      0.72       285\n",
            "           3       0.76      0.78      0.77       277\n",
            "\n",
            "    accuracy                           0.73      1000\n",
            "   macro avg       0.75      0.71      0.72      1000\n",
            "weighted avg       0.75      0.73      0.73      1000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m36-LEN9CrS-",
        "outputId": "276843e6-8359-4c05-a287-08ff9725f2f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTuning XGBoost for TFIDF:   0%|          | 0/18 [00:00<?, ?combination/s]/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [23:17:19] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Tuning XGBoost for TFIDF:   6%|▌         | 1/18 [01:46<30:05, 106.21s/combination]/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [23:19:05] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Tuning XGBoost for TFIDF:  11%|█         | 2/18 [05:20<45:15, 169.71s/combination]/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [23:22:39] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Tuning XGBoost for TFIDF:  17%|█▋        | 3/18 [10:38<59:19, 237.29s/combination]/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [23:27:57] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Tuning XGBoost for TFIDF:  22%|██▏       | 4/18 [15:00<57:38, 247.03s/combination]/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [23:32:19] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Tuning XGBoost for TFIDF:  28%|██▊       | 5/18 [23:38<1:14:42, 344.84s/combination]/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [23:40:57] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Tuning XGBoost for TFIDF:  33%|███▎      | 6/18 [36:22<1:37:30, 487.51s/combination]/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [23:53:41] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Tuning XGBoost for TFIDF:  39%|███▉      | 7/18 [45:21<1:32:27, 504.35s/combination]/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [00:02:40] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Tuning XGBoost for TFIDF:  44%|████▍     | 8/18 [1:02:47<1:52:48, 676.84s/combination]/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [00:20:07] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Tuning XGBoost for TFIDF:  50%|█████     | 9/18 [1:28:07<2:21:02, 940.25s/combination]/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [00:45:26] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Tuning XGBoost for TFIDF:  56%|█████▌    | 10/18 [1:29:51<1:30:57, 682.13s/combination]/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [00:47:10] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Tuning XGBoost for TFIDF:  61%|██████    | 11/18 [1:33:16<1:02:32, 536.10s/combination]/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [00:50:36] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Tuning XGBoost for TFIDF:  67%|██████▋   | 12/18 [1:38:16<46:25, 464.32s/combination]  /usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [00:55:36] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Tuning XGBoost for TFIDF:  72%|███████▏  | 13/18 [1:42:19<33:06, 397.22s/combination]/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [00:59:38] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Tuning XGBoost for TFIDF:  78%|███████▊  | 14/18 [1:49:37<27:18, 409.56s/combination]/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [01:06:57] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Tuning XGBoost for TFIDF:  83%|████████▎ | 15/18 [2:00:05<23:46, 475.43s/combination]/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [01:17:24] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Tuning XGBoost for TFIDF:  89%|████████▉ | 16/18 [2:07:22<15:27, 463.73s/combination]/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [01:24:41] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Tuning XGBoost for TFIDF:  94%|█████████▍| 17/18 [2:20:00<09:12, 552.16s/combination]/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [01:37:19] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Tuning XGBoost for TFIDF: 100%|██████████| 18/18 [2:37:35<00:00, 525.29s/combination]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best model for TFIDF:\n",
            "Best Validation Accuracy: 64.14%\n",
            "Best Hyperparameters: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 300}\n",
            "Best KNN model for TFIDF: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 300}, Validation Accuracy: 64.14%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Run the hypertuning process for TFIDF\n",
        "best_xg_tfidf, best_score_tfidf, best_params_tfidf, y_pred_tfidf = tune_and_run_xgb_model(\n",
        "    X_train_tfidf, y_train_tfidf, X_val_tfidf, y_val_tfidf, X_test_tfidf, \"TFIDF\"\n",
        ")\n",
        "\n",
        "\n",
        "print(f\"Best KNN model for TFIDF: {best_params_tfidf}, Validation Accuracy: {best_score_tfidf * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Test Accuracy and Classification Report for TFIDF\n",
        "print(\"\\n--- TFIDF Vectorizer Test Set Evaluation ---\")\n",
        "accuracy_tfidf = accuracy_score(y_test, y_pred_tfidf)\n",
        "report_tfidf = classification_report(y_test, y_pred_tfidf)\n",
        "\n",
        "print(f\"Test Accuracy for TFIDF: {accuracy_tfidf * 100:.2f}%\")\n",
        "print(\"Classification Report:\")\n",
        "print(report_tfidf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ek7aG5AIA2h",
        "outputId": "e896bf80-f1d3-43e0-b5ba-b6d1ec1214ae"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- TFIDF Vectorizer Test Set Evaluation ---\n",
            "Test Accuracy for TFIDF: 76.10%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.60      0.72       172\n",
            "           1       0.68      0.90      0.78       266\n",
            "           2       0.80      0.71      0.75       285\n",
            "           3       0.78      0.78      0.78       277\n",
            "\n",
            "    accuracy                           0.76      1000\n",
            "   macro avg       0.79      0.75      0.76      1000\n",
            "weighted avg       0.78      0.76      0.76      1000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QAxycY9zIEDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuwU8YT6Ctgm",
        "outputId": "a646b20d-c2f3-4a21-fd01-ec43ca79436f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTuning XGBoost for Word2Vec:   0%|          | 0/18 [00:00<?, ?combination/s]/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [01:54:55] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Tuning XGBoost for Word2Vec:   6%|▌         | 1/18 [00:13<03:51, 13.63s/combination]/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [01:55:08] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Tuning XGBoost for Word2Vec:  11%|█         | 2/18 [00:41<05:49, 21.87s/combination]/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [01:55:36] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Tuning XGBoost for Word2Vec:  17%|█▋        | 3/18 [01:21<07:33, 30.20s/combination]/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [01:56:16] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Tuning XGBoost for Word2Vec:  22%|██▏       | 4/18 [01:47<06:41, 28.67s/combination]/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [01:56:42] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Tuning XGBoost for Word2Vec:  28%|██▊       | 5/18 [02:39<07:59, 36.88s/combination]/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [01:57:34] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Tuning XGBoost for Word2Vec:  33%|███▎      | 6/18 [03:55<10:04, 50.33s/combination]/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [01:58:50] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Tuning XGBoost for Word2Vec:  39%|███▉      | 7/18 [04:53<09:41, 52.86s/combination]/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [01:59:48] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Tuning XGBoost for Word2Vec:  44%|████▍     | 8/18 [06:51<12:14, 73.47s/combination]/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:01:46] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Tuning XGBoost for Word2Vec:  50%|█████     | 9/18 [09:44<15:43, 104.78s/combination]/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:04:39] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Tuning XGBoost for Word2Vec:  56%|█████▌    | 10/18 [09:57<10:11, 76.43s/combination]/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:04:52] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Tuning XGBoost for Word2Vec:  61%|██████    | 11/18 [10:22<07:03, 60.48s/combination]/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:05:17] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Tuning XGBoost for Word2Vec:  67%|██████▋   | 12/18 [10:54<05:11, 51.99s/combination]/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:05:49] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Tuning XGBoost for Word2Vec:  72%|███████▏  | 13/18 [11:19<03:39, 43.83s/combination]/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:06:14] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Tuning XGBoost for Word2Vec:  78%|███████▊  | 14/18 [12:08<03:01, 45.28s/combination]/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:07:03] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Tuning XGBoost for Word2Vec:  83%|████████▎ | 15/18 [13:16<02:36, 52.10s/combination]/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:08:11] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Tuning XGBoost for Word2Vec:  89%|████████▉ | 16/18 [14:11<01:45, 52.96s/combination]/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:09:06] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Tuning XGBoost for Word2Vec:  94%|█████████▍| 17/18 [16:02<01:10, 70.60s/combination]/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:10:57] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Tuning XGBoost for Word2Vec: 100%|██████████| 18/18 [18:43<00:00, 62.42s/combination]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best model for Word2Vec:\n",
            "Best Validation Accuracy: 72.57%\n",
            "Best Hyperparameters: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 300}\n",
            "Best KNN model for Word2Vec: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 300}, Validation Accuracy: 72.57%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Run the hypertuning process for Word2Vec\n",
        "best_xg_w2v, best_score_w2v, best_params_w2v, y_pred_w2v = tune_and_run_xgb_model(\n",
        "    X_train_w2v, y_train_w2v, X_val_w2v, y_val_w2v, X_test_w2v, \"Word2Vec\"\n",
        ")\n",
        "\n",
        "print(f\"Best KNN model for Word2Vec: {best_params_w2v}, Validation Accuracy: {best_score_w2v * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Example: Test Accuracy and Classification Report for Word2Vec\n",
        "print(\"\\n--- Word2Vec Test Set Evaluation ---\")\n",
        "accuracy_w2v = accuracy_score(y_test, y_pred_w2v)\n",
        "report_w2v = classification_report(y_test, y_pred_w2v)\n",
        "\n",
        "print(f\"Test Accuracy for Word2Vec: {accuracy_w2v * 100:.2f}%\")\n",
        "print(\"Classification Report:\")\n",
        "print(report_w2v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1px5MYbIHJg",
        "outputId": "7af8f2af-e8b9-4d25-a860-b9decf560aba"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Word2Vec Test Set Evaluation ---\n",
            "Test Accuracy for Word2Vec: 88.00%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.84      0.86       172\n",
            "           1       0.88      0.92      0.90       266\n",
            "           2       0.89      0.84      0.86       285\n",
            "           3       0.87      0.90      0.89       277\n",
            "\n",
            "    accuracy                           0.88      1000\n",
            "   macro avg       0.88      0.88      0.88      1000\n",
            "weighted avg       0.88      0.88      0.88      1000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zD3QqMK64zZ_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This time, we can see word2vec embedding outperformed!!! then let's do more hypertuning because every time we have 'max_depth': 7, 'n_estimators': 300 as our best model,\n",
        "So I think we need to increase the depth and the number of the trees"
      ],
      "metadata": {
        "id": "BymSX2xB4sWZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_clf = XGBClassifier(\n",
        "        learning_rate=0.1,\n",
        "        n_estimators=400,\n",
        "        max_depth=8,\n",
        "        objective='multi:softmax',\n",
        "        use_label_encoder=False,\n",
        "        eval_metric='logloss'\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "\n",
        "\n",
        "xgb_clf.fit(X_train_w2v, y_train_w2v)\n",
        "\n",
        "# Make predictions on validation and test sets\n",
        "y_val_pred = xgb_clf.predict(X_val_w2v)\n",
        "y_pred_w2v = xgb_clf.predict(X_test_w2v)\n",
        "\n",
        "# Calculate validation accuracy\n",
        "val_accuracy = accuracy_score(y_val_w2v, y_val_pred)\n",
        "report_cv = classification_report(y_val_w2v, y_val_w2v)\n",
        "# Print the validation accuracy\n",
        "print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")\n",
        "\n",
        "accuracy_cv = accuracy_score(y_test, y_pred_w2v)\n",
        "report_cv = classification_report(y_test, y_pred_w2v)\n",
        "\n",
        "print(f\"Test Accuracy for word2vec: {accuracy_cv * 100:.2f}%\")\n",
        "print(\"Classification Report:\")\n",
        "print(report_cv)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buSz8t1y4vWT",
        "outputId": "bfb38324-a7ba-4ea6-b77a-9b61c09aea2e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [02:48:58] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 76.66%\n",
            "Test Accuracy for word2vec: 90.20%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.85      0.88       172\n",
            "           1       0.91      0.93      0.92       266\n",
            "           2       0.91      0.88      0.90       285\n",
            "           3       0.89      0.92      0.91       277\n",
            "\n",
            "    accuracy                           0.90      1000\n",
            "   macro avg       0.90      0.90      0.90      1000\n",
            "weighted avg       0.90      0.90      0.90      1000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally we reached 90% in the last, and next week, Our group is going to use the neural networks for a higher value."
      ],
      "metadata": {
        "id": "cQs3hUBd7c83"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tFNN--06jaq"
      },
      "source": [
        "Looks like count vectorizer embedding is the best!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}