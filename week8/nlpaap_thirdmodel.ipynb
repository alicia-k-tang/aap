{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bZWgptcSb-_",
        "outputId": "d2d26085-ba83-43bc-b56b-aff88c198017"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Load Count Vectorizer data\n",
        "X_train_cv = joblib.load('/content/drive/MyDrive/X_train_cv.joblib')\n",
        "X_val_cv = joblib.load('/content/drive/MyDrive/X_val_cv.joblib')\n",
        "y_train_cv = joblib.load('/content/drive/MyDrive/y_train_cv.joblib')\n",
        "y_val_cv = joblib.load('/content/drive/MyDrive/y_val_cv.joblib')\n",
        "X_test_cv = joblib.load('/content/drive/MyDrive/X_test_cv.joblib')\n",
        "cv = joblib.load('/content/drive/MyDrive/count_vectorizer.joblib')\n",
        "\n",
        "# Load TFIDF Vectorizer data\n",
        "X_train_tfidf = joblib.load('/content/drive/MyDrive/X_train_tfidf.joblib')\n",
        "X_val_tfidf = joblib.load('/content/drive/MyDrive/X_val_tfidf.joblib')\n",
        "y_train_tfidf = joblib.load('/content/drive/MyDrive/y_train_tfidf.joblib')\n",
        "y_val_tfidf = joblib.load('/content/drive/MyDrive/y_val_tfidf.joblib')\n",
        "X_test_tfidf = joblib.load('/content/drive/MyDrive/X_test_tfidf.joblib')\n",
        "tfidf = joblib.load('/content/drive/MyDrive/tfidf_vectorizer.joblib')\n",
        "\n",
        "# Load Word2Vec data\n",
        "X_train_w2v = joblib.load('/content/drive/MyDrive/X_train_w2v.joblib')\n",
        "X_val_w2v = joblib.load('/content/drive/MyDrive/X_val_w2v.joblib')\n",
        "y_train_w2v = joblib.load('/content/drive/MyDrive/y_train_w2v.joblib')\n",
        "y_val_w2v = joblib.load('/content/drive/MyDrive/y_val_w2v.joblib')\n",
        "X_test_w2v = joblib.load('/content/drive/MyDrive/X_test_w2v.joblib')\n",
        "w2v = joblib.load('/content/drive/MyDrive/word2vec_model.joblib')\n",
        "\n",
        "# Load y_test\n",
        "y_test = joblib.load('/content/drive/MyDrive/y_test.joblib')"
      ],
      "metadata": {
        "id": "eabFB8plSgfI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Bidirectional Neural Network for Sentiment Analysis\n"
      ],
      "metadata": {
        "id": "DVqlW3g2SiKP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "\n",
        "# Input layer\n",
        "model.add(Dense(1024, activation='relu', input_shape=(X_train_cv.shape[1],)))\n",
        "\n",
        "# Hidden layer 1\n",
        "model.add(Dense(256, activation='relu'))\n",
        "\n",
        "# Dropout to avoid overfitting\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Hidden layer 2\n",
        "model.add(Dense(64, activation='relu'))\n",
        "\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(16, activation='relu'))\n",
        "\n",
        "\n",
        "# Output layer (Assuming multi-class classification with softmax)\n",
        "model.add(Dense(4, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train_cv, y_train_cv,\n",
        "                    epochs=3,\n",
        "                    batch_size=32,\n",
        "                    validation_data=(X_val_cv, y_val_cv))\n",
        "\n",
        "# Evaluate the model on test data\n",
        "test_loss, test_acc = model.evaluate(X_test_cv, y_test)\n",
        "print(f\"Test accuracy: {test_acc * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ur9VliGkYKJb",
        "outputId": "40f696de-6ab6-4c6d-a5f9-b7f46cede3e1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m667s\u001b[0m 382ms/step - accuracy: 0.5702 - loss: 1.0224 - val_accuracy: 0.8750 - val_loss: 0.3622\n",
            "Epoch 2/3\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m695s\u001b[0m 390ms/step - accuracy: 0.9342 - loss: 0.2073 - val_accuracy: 0.9218 - val_loss: 0.2486\n",
            "Epoch 3/3\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m672s\u001b[0m 387ms/step - accuracy: 0.9746 - loss: 0.0896 - val_accuracy: 0.9286 - val_loss: 0.2673\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9754 - loss: 0.1499\n",
            "Test accuracy: 97.60%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "\n",
        "# Input layer\n",
        "model.add(Dense(1024, activation='relu', input_shape=(X_train_tfidf.shape[1],)))\n",
        "\n",
        "# Hidden layer 1\n",
        "model.add(Dense(256, activation='relu'))\n",
        "\n",
        "# Dropout to avoid overfitting\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Hidden layer 2\n",
        "model.add(Dense(64, activation='relu'))\n",
        "\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(16, activation='relu'))\n",
        "\n",
        "\n",
        "# Output layer (Assuming multi-class classification with softmax)\n",
        "model.add(Dense(4, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train_tfidf, y_train_tfidf,\n",
        "                    epochs=3,\n",
        "                    batch_size=32,\n",
        "                    validation_data=(X_val_tfidf, y_val_tfidf))\n",
        "\n",
        "# Evaluate the model on test data\n",
        "test_loss, test_acc = model.evaluate(X_test_tfidf, y_test)\n",
        "print(f\"Test accuracy: {test_acc * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22fKjam3X6Pi",
        "outputId": "e300ace0-d440-402f-9f68-77871ce779ef"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 223774720 elements. This may consume a large amount of memory.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5884s\u001b[0m 3s/step - accuracy: 0.5957 - loss: 0.9446 - val_accuracy: 0.9278 - val_loss: 0.2296\n",
            "Epoch 2/3\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5827s\u001b[0m 3s/step - accuracy: 0.9683 - loss: 0.1049 - val_accuracy: 0.9372 - val_loss: 0.2152\n",
            "Epoch 3/3\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5845s\u001b[0m 3s/step - accuracy: 0.9817 - loss: 0.0524 - val_accuracy: 0.9406 - val_loss: 0.2021\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9741 - loss: 0.0983\n",
            "Test accuracy: 97.60%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "\n",
        "# Input layer\n",
        "model.add(Dense(1024, activation='relu', input_shape=(X_train_w2v.shape[1],)))\n",
        "\n",
        "# Hidden layer 1\n",
        "model.add(Dense(256, activation='relu'))\n",
        "\n",
        "# Dropout to avoid overfitting\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Hidden layer 2\n",
        "model.add(Dense(64, activation='relu'))\n",
        "\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(16, activation='relu'))\n",
        "\n",
        "\n",
        "# Output layer (Assuming multi-class classification with softmax)\n",
        "model.add(Dense(4, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train_w2v, y_train_w2v,\n",
        "                    epochs=100,\n",
        "                    batch_size=32,\n",
        "                    validation_data=(X_val_w2v, y_val_w2v))\n",
        "\n",
        "# Evaluate the model on test data\n",
        "test_loss, test_acc = model.evaluate(X_test_w2v, y_test)\n",
        "print(f\"Test accuracy: {test_acc * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8UAKOX_TFdo",
        "outputId": "7dbad160-34c5-4545-c822-ccf689185559"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.4491 - loss: 1.2464 - val_accuracy: 0.5144 - val_loss: 1.1378\n",
            "Epoch 2/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.5066 - loss: 1.1570 - val_accuracy: 0.5258 - val_loss: 1.1031\n",
            "Epoch 3/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.5180 - loss: 1.1274 - val_accuracy: 0.5302 - val_loss: 1.0985\n",
            "Epoch 4/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.5259 - loss: 1.1157 - val_accuracy: 0.5364 - val_loss: 1.0885\n",
            "Epoch 5/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.5347 - loss: 1.0974 - val_accuracy: 0.5357 - val_loss: 1.0922\n",
            "Epoch 6/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 13ms/step - accuracy: 0.5384 - loss: 1.0873 - val_accuracy: 0.5418 - val_loss: 1.0801\n",
            "Epoch 7/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.5475 - loss: 1.0730 - val_accuracy: 0.5487 - val_loss: 1.0620\n",
            "Epoch 8/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.5491 - loss: 1.0627 - val_accuracy: 0.5451 - val_loss: 1.0589\n",
            "Epoch 9/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.5532 - loss: 1.0572 - val_accuracy: 0.5521 - val_loss: 1.0546\n",
            "Epoch 10/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.5591 - loss: 1.0485 - val_accuracy: 0.5558 - val_loss: 1.0449\n",
            "Epoch 11/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.5602 - loss: 1.0425 - val_accuracy: 0.5566 - val_loss: 1.0474\n",
            "Epoch 12/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.5663 - loss: 1.0344 - val_accuracy: 0.5575 - val_loss: 1.0381\n",
            "Epoch 13/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.5703 - loss: 1.0245 - val_accuracy: 0.5598 - val_loss: 1.0297\n",
            "Epoch 14/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.5743 - loss: 1.0192 - val_accuracy: 0.5617 - val_loss: 1.0322\n",
            "Epoch 15/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 12ms/step - accuracy: 0.5703 - loss: 1.0183 - val_accuracy: 0.5698 - val_loss: 1.0216\n",
            "Epoch 16/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 10ms/step - accuracy: 0.5737 - loss: 1.0103 - val_accuracy: 0.5673 - val_loss: 1.0182\n",
            "Epoch 17/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.5828 - loss: 0.9965 - val_accuracy: 0.5690 - val_loss: 1.0178\n",
            "Epoch 18/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.5826 - loss: 0.9983 - val_accuracy: 0.5734 - val_loss: 1.0053\n",
            "Epoch 19/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.5912 - loss: 0.9809 - val_accuracy: 0.5775 - val_loss: 0.9983\n",
            "Epoch 20/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.5944 - loss: 0.9702 - val_accuracy: 0.5799 - val_loss: 0.9927\n",
            "Epoch 21/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.5971 - loss: 0.9691 - val_accuracy: 0.5708 - val_loss: 1.0025\n",
            "Epoch 22/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.5959 - loss: 0.9703 - val_accuracy: 0.5827 - val_loss: 0.9891\n",
            "Epoch 23/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.6019 - loss: 0.9543 - val_accuracy: 0.5792 - val_loss: 0.9947\n",
            "Epoch 24/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.6026 - loss: 0.9540 - val_accuracy: 0.5829 - val_loss: 0.9878\n",
            "Epoch 25/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.6030 - loss: 0.9501 - val_accuracy: 0.5876 - val_loss: 0.9810\n",
            "Epoch 26/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.6084 - loss: 0.9463 - val_accuracy: 0.5893 - val_loss: 0.9777\n",
            "Epoch 27/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.6180 - loss: 0.9278 - val_accuracy: 0.5936 - val_loss: 0.9787\n",
            "Epoch 28/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.6160 - loss: 0.9284 - val_accuracy: 0.5990 - val_loss: 0.9720\n",
            "Epoch 29/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.6191 - loss: 0.9221 - val_accuracy: 0.5979 - val_loss: 0.9629\n",
            "Epoch 30/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.6216 - loss: 0.9176 - val_accuracy: 0.5971 - val_loss: 0.9648\n",
            "Epoch 31/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.6215 - loss: 0.9142 - val_accuracy: 0.5990 - val_loss: 0.9654\n",
            "Epoch 32/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.6250 - loss: 0.9082 - val_accuracy: 0.6035 - val_loss: 0.9545\n",
            "Epoch 33/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.6287 - loss: 0.9007 - val_accuracy: 0.5997 - val_loss: 0.9597\n",
            "Epoch 34/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.6273 - loss: 0.9011 - val_accuracy: 0.6006 - val_loss: 0.9603\n",
            "Epoch 35/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.6307 - loss: 0.8952 - val_accuracy: 0.6108 - val_loss: 0.9487\n",
            "Epoch 36/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.6369 - loss: 0.8819 - val_accuracy: 0.6077 - val_loss: 0.9553\n",
            "Epoch 37/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.6391 - loss: 0.8800 - val_accuracy: 0.6141 - val_loss: 0.9448\n",
            "Epoch 38/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.6381 - loss: 0.8838 - val_accuracy: 0.6146 - val_loss: 0.9500\n",
            "Epoch 39/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.6467 - loss: 0.8621 - val_accuracy: 0.6131 - val_loss: 0.9404\n",
            "Epoch 40/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.6395 - loss: 0.8731 - val_accuracy: 0.6119 - val_loss: 0.9477\n",
            "Epoch 41/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.6443 - loss: 0.8696 - val_accuracy: 0.6080 - val_loss: 0.9529\n",
            "Epoch 42/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.6498 - loss: 0.8549 - val_accuracy: 0.6185 - val_loss: 0.9321\n",
            "Epoch 43/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.6521 - loss: 0.8483 - val_accuracy: 0.6189 - val_loss: 0.9383\n",
            "Epoch 44/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.6550 - loss: 0.8432 - val_accuracy: 0.6254 - val_loss: 0.9262\n",
            "Epoch 45/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.6563 - loss: 0.8498 - val_accuracy: 0.6234 - val_loss: 0.9302\n",
            "Epoch 46/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.6566 - loss: 0.8416 - val_accuracy: 0.6159 - val_loss: 0.9417\n",
            "Epoch 47/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.6565 - loss: 0.8417 - val_accuracy: 0.6216 - val_loss: 0.9292\n",
            "Epoch 48/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.6560 - loss: 0.8408 - val_accuracy: 0.6285 - val_loss: 0.9221\n",
            "Epoch 49/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.6667 - loss: 0.8257 - val_accuracy: 0.6252 - val_loss: 0.9313\n",
            "Epoch 50/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.6630 - loss: 0.8268 - val_accuracy: 0.6329 - val_loss: 0.9129\n",
            "Epoch 51/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - accuracy: 0.6693 - loss: 0.8201 - val_accuracy: 0.6284 - val_loss: 0.9216\n",
            "Epoch 52/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.6689 - loss: 0.8089 - val_accuracy: 0.6355 - val_loss: 0.9111\n",
            "Epoch 53/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.6677 - loss: 0.8151 - val_accuracy: 0.6316 - val_loss: 0.9132\n",
            "Epoch 54/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.6708 - loss: 0.8144 - val_accuracy: 0.6319 - val_loss: 0.9121\n",
            "Epoch 55/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.6701 - loss: 0.8066 - val_accuracy: 0.6337 - val_loss: 0.9145\n",
            "Epoch 56/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.6719 - loss: 0.8037 - val_accuracy: 0.6385 - val_loss: 0.9021\n",
            "Epoch 57/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.6736 - loss: 0.8026 - val_accuracy: 0.6397 - val_loss: 0.9046\n",
            "Epoch 58/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.6752 - loss: 0.7970 - val_accuracy: 0.6336 - val_loss: 0.9229\n",
            "Epoch 59/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.6746 - loss: 0.7984 - val_accuracy: 0.6385 - val_loss: 0.9028\n",
            "Epoch 60/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.6787 - loss: 0.7945 - val_accuracy: 0.6436 - val_loss: 0.9064\n",
            "Epoch 61/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.6817 - loss: 0.7957 - val_accuracy: 0.6423 - val_loss: 0.9158\n",
            "Epoch 62/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.6831 - loss: 0.7903 - val_accuracy: 0.6414 - val_loss: 0.9066\n",
            "Epoch 63/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.6809 - loss: 0.7898 - val_accuracy: 0.6404 - val_loss: 0.8971\n",
            "Epoch 64/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.6850 - loss: 0.7812 - val_accuracy: 0.6367 - val_loss: 0.9181\n",
            "Epoch 65/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.6820 - loss: 0.7848 - val_accuracy: 0.6452 - val_loss: 0.8950\n",
            "Epoch 66/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.6829 - loss: 0.7788 - val_accuracy: 0.6440 - val_loss: 0.9056\n",
            "Epoch 67/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.6891 - loss: 0.7690 - val_accuracy: 0.6431 - val_loss: 0.8990\n",
            "Epoch 68/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.6873 - loss: 0.7677 - val_accuracy: 0.6508 - val_loss: 0.8929\n",
            "Epoch 69/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.6896 - loss: 0.7652 - val_accuracy: 0.6458 - val_loss: 0.9008\n",
            "Epoch 70/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.6925 - loss: 0.7627 - val_accuracy: 0.6535 - val_loss: 0.8857\n",
            "Epoch 71/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.6929 - loss: 0.7643 - val_accuracy: 0.6477 - val_loss: 0.8904\n",
            "Epoch 72/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.6964 - loss: 0.7537 - val_accuracy: 0.6500 - val_loss: 0.8888\n",
            "Epoch 73/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.6951 - loss: 0.7570 - val_accuracy: 0.6487 - val_loss: 0.8942\n",
            "Epoch 74/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.6991 - loss: 0.7553 - val_accuracy: 0.6526 - val_loss: 0.8913\n",
            "Epoch 75/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.6973 - loss: 0.7516 - val_accuracy: 0.6545 - val_loss: 0.8958\n",
            "Epoch 76/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.6960 - loss: 0.7575 - val_accuracy: 0.6531 - val_loss: 0.8865\n",
            "Epoch 77/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.7026 - loss: 0.7461 - val_accuracy: 0.6577 - val_loss: 0.8831\n",
            "Epoch 78/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.7038 - loss: 0.7372 - val_accuracy: 0.6611 - val_loss: 0.8792\n",
            "Epoch 79/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.7054 - loss: 0.7334 - val_accuracy: 0.6613 - val_loss: 0.8769\n",
            "Epoch 80/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.7042 - loss: 0.7404 - val_accuracy: 0.6519 - val_loss: 0.8964\n",
            "Epoch 81/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.7013 - loss: 0.7388 - val_accuracy: 0.6527 - val_loss: 0.8972\n",
            "Epoch 82/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.7077 - loss: 0.7358 - val_accuracy: 0.6566 - val_loss: 0.8809\n",
            "Epoch 83/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.7092 - loss: 0.7333 - val_accuracy: 0.6598 - val_loss: 0.8770\n",
            "Epoch 84/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.7043 - loss: 0.7336 - val_accuracy: 0.6564 - val_loss: 0.8821\n",
            "Epoch 85/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.7062 - loss: 0.7270 - val_accuracy: 0.6639 - val_loss: 0.8745\n",
            "Epoch 86/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.7073 - loss: 0.7310 - val_accuracy: 0.6566 - val_loss: 0.8869\n",
            "Epoch 87/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.7112 - loss: 0.7226 - val_accuracy: 0.6652 - val_loss: 0.8681\n",
            "Epoch 88/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.7110 - loss: 0.7269 - val_accuracy: 0.6617 - val_loss: 0.8722\n",
            "Epoch 89/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.7116 - loss: 0.7164 - val_accuracy: 0.6570 - val_loss: 0.8708\n",
            "Epoch 90/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.7121 - loss: 0.7150 - val_accuracy: 0.6614 - val_loss: 0.8781\n",
            "Epoch 91/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.7128 - loss: 0.7165 - val_accuracy: 0.6638 - val_loss: 0.8795\n",
            "Epoch 92/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.7184 - loss: 0.7087 - val_accuracy: 0.6675 - val_loss: 0.8761\n",
            "Epoch 93/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.7159 - loss: 0.7085 - val_accuracy: 0.6639 - val_loss: 0.8777\n",
            "Epoch 94/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.7155 - loss: 0.7038 - val_accuracy: 0.6629 - val_loss: 0.8753\n",
            "Epoch 95/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.7173 - loss: 0.7072 - val_accuracy: 0.6688 - val_loss: 0.8682\n",
            "Epoch 96/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.7196 - loss: 0.7022 - val_accuracy: 0.6725 - val_loss: 0.8647\n",
            "Epoch 97/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.7190 - loss: 0.7033 - val_accuracy: 0.6727 - val_loss: 0.8614\n",
            "Epoch 98/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 12ms/step - accuracy: 0.7183 - loss: 0.7017 - val_accuracy: 0.6692 - val_loss: 0.8742\n",
            "Epoch 99/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.7210 - loss: 0.7009 - val_accuracy: 0.6700 - val_loss: 0.8554\n",
            "Epoch 100/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.7209 - loss: 0.6971 - val_accuracy: 0.6732 - val_loss: 0.8501\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7737 - loss: 0.6116\n",
            "Test accuracy: 77.30%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MLP uses non-linear activation functions (like ReLU or sigmoid) that enable it to learn complex boundaries between classes, which is particularly useful for a task like sentiment analysis where the relationships between words and sentiment are not strictly linear. It helps in understanding nuanced differences between Positive, Negative, and Neutral sentiments.\n",
        "\n",
        "TF-IDF creates a large feature space, representing each document as a vector of weighted terms. While this can be challenging for simpler models (like KNN or logistic regression), MLP thrives in high-dimensional spaces as it has the capacity to model complex decision boundaries.\n",
        "\n",
        "For other embeddings, Count Vectorizer embedding didn’t consider the frequency of word in sentence, Word2Vec embeddings has a hyperparameter of the dimension of the vector, which can cause significant difference in model performance and takes more resource for training.\n"
      ],
      "metadata": {
        "id": "dmjUnO2GQz7I"
      }
    }
  ]
}