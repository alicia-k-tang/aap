{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bZWgptcSb-_",
        "outputId": "ca4240bb-de1b-4717-eed8-090b95389d83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load Count Vectorizer data\n",
        "X_train_cv = joblib.load('/content/drive/MyDrive/X_train_cv.joblib')\n",
        "X_val_cv = joblib.load('/content/drive/MyDrive/X_val_cv.joblib')\n",
        "X_test_cv = joblib.load('/content/drive/MyDrive/X_test_cv.joblib')\n",
        "\n",
        "# Check if the data is sparse, then convert it to dense using .toarray()\n",
        "if hasattr(X_train_cv, \"toarray\"):\n",
        "    X_train_cv = X_train_cv.toarray()\n",
        "\n",
        "if hasattr(X_val_cv, \"toarray\"):\n",
        "    X_val_cv = X_val_cv.toarray()\n",
        "\n",
        "if hasattr(X_test_cv, \"toarray\"):\n",
        "    X_test_cv = X_test_cv.toarray()\n",
        "\n",
        "# Load the labels and other data\n",
        "y_train_cv = joblib.load('/content/drive/MyDrive/y_train_cv.joblib')\n",
        "y_val_cv = joblib.load('/content/drive/MyDrive/y_val_cv.joblib')\n",
        "\n",
        "# Load TFIDF Vectorizer data\n",
        "X_train_tfidf = joblib.load('/content/drive/MyDrive/X_train_tfidf.joblib')\n",
        "X_val_tfidf = joblib.load('/content/drive/MyDrive/X_val_tfidf.joblib')\n",
        "X_test_tfidf = joblib.load('/content/drive/MyDrive/X_test_tfidf.joblib')\n",
        "\n",
        "# Convert if needed\n",
        "if hasattr(X_train_tfidf, \"toarray\"):\n",
        "    X_train_tfidf = X_train_tfidf.toarray()\n",
        "\n",
        "if hasattr(X_val_tfidf, \"toarray\"):\n",
        "    X_val_tfidf = X_val_tfidf.toarray()\n",
        "\n",
        "if hasattr(X_test_tfidf, \"toarray\"):\n",
        "    X_test_tfidf = X_test_tfidf.toarray()\n",
        "\n",
        "\n",
        "y_train_tfidf = joblib.load('/content/drive/MyDrive/y_train_tfidf.joblib')\n",
        "y_val_tfidf = joblib.load('/content/drive/MyDrive/y_val_tfidf.joblib')\n",
        "\n",
        "\n",
        "# Load Word2Vec data\n",
        "X_train_w2v = joblib.load('/content/drive/MyDrive/X_train_w2v.joblib')\n",
        "X_val_w2v = joblib.load('/content/drive/MyDrive/X_val_w2v.joblib')\n",
        "X_test_w2v = joblib.load('/content/drive/MyDrive/X_test_w2v.joblib')\n",
        "\n",
        "# Word2Vec data should already be dense, but you can check and convert if needed\n",
        "if hasattr(X_train_w2v, \"toarray\"):\n",
        "    X_train_w2v = X_train_w2v.toarray()\n",
        "\n",
        "if hasattr(X_val_w2v, \"toarray\"):\n",
        "    X_val_w2v = X_val_w2v.toarray()\n",
        "\n",
        "if hasattr(X_test_w2v, \"toarray\"):\n",
        "    X_test_w2v = X_test_w2v.toarray()\n",
        "\n",
        "y_train_w2v = joblib.load('/content/drive/MyDrive/y_train_w2v.joblib')\n",
        "y_val_w2v = joblib.load('/content/drive/MyDrive/y_val_w2v.joblib')\n",
        "\n",
        "\n",
        "# Load the rest of your data such as vectorizers and models as usual\n",
        "cv = joblib.load('/content/drive/MyDrive/count_vectorizer.joblib')\n",
        "tfidf = joblib.load('/content/drive/MyDrive/tfidf_vectorizer.joblib')\n",
        "w2v = joblib.load('/content/drive/MyDrive/word2vec_model.joblib')\n",
        "\n",
        "y_test = joblib.load('/content/drive/MyDrive/y_test.joblib')\n"
      ],
      "metadata": {
        "id": "szEdtBXiFYcE"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbkS8lewD2ZG",
        "outputId": "97b17151-c32d-47b7-d76e-184a4efb6041"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tf.config.optimizer.set_jit(False)  # Disable XLA JIT compilation\n"
      ],
      "metadata": {
        "id": "t7Xg2SP0ErVr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout"
      ],
      "metadata": {
        "id": "DwvKqytVK1Mg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrZZd0VsK2hf",
        "outputId": "a4b4f508-2999-4713-983f-8c23612ef847"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MLP models for 3 embedings"
      ],
      "metadata": {
        "id": "GPbcTlKE9cPw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## since we got the best params before we can derectly use them"
      ],
      "metadata": {
        "id": "rOCvz6b6-w9Z"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_cv.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0TQyz4jCSZ2",
        "outputId": "987abcf7-679e-49ef-c29b-c5e5060d4ccd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(55592, 22126)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import ParameterGrid\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from tqdm import tqdm\n",
        "import joblib\n",
        "\n",
        "# Define the hyperparameter grid\n",
        "param_grid = {\n",
        "    'n_neighbors': [7],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'metric': ['euclidean', 'manhattan']\n",
        "}\n",
        "\n",
        "# Function to run hypertuning for each vectorizer and return the best model\n",
        "def tune_and_run_knn_model(X_train, y_train, X_val, y_val, X_test, vectorizer_name):\n",
        "    param_combinations = list(ParameterGrid(param_grid))  # Get all parameter combinations\n",
        "    best_score = 0\n",
        "    best_params = None\n",
        "    best_knn = None\n",
        "\n",
        "    # Progress bar using tqdm to track tuning process\n",
        "    for params in tqdm(param_combinations, desc=f\"Tuning KNN for {vectorizer_name}\", unit=\"combination\"):\n",
        "        # Initialize KNN with current hyperparameters\n",
        "        knn = KNeighborsClassifier(**params)\n",
        "\n",
        "        # Fit the KNN model\n",
        "        knn.fit(X_train, y_train)\n",
        "\n",
        "        # Make predictions on validation data\n",
        "        y_pred_val = knn.predict(X_val)\n",
        "\n",
        "        # Evaluate the model\n",
        "        accuracy = accuracy_score(y_val, y_pred_val)\n",
        "\n",
        "        # Keep track of the best model based on validation accuracy\n",
        "        if accuracy > best_score:\n",
        "            best_score = accuracy\n",
        "            best_params = params\n",
        "            best_knn = knn\n",
        "\n",
        "    # Print the best results for the current vectorizer\n",
        "    print(f\"\\nBest model for {vectorizer_name}:\")\n",
        "    print(f\"Best Validation Accuracy: {best_score * 100:.2f}%\")\n",
        "    print(f\"Best Hyperparameters: {best_params}\")\n",
        "\n",
        "    # Now use the best model to predict on the test data\n",
        "    y_pred_test = best_knn.predict(X_test)\n",
        "\n",
        "    print(f\"Test predictions saved for {vectorizer_name} KNN model.\\n\")\n",
        "\n",
        "    return best_knn, best_score, best_params"
      ],
      "metadata": {
        "id": "ESSfP0z9DMHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Run the hypertuning process for Count Vectorizer\n",
        "best_knn_cv, best_score_cv, best_params_cv = tune_and_run_knn_model(\n",
        "    X_train_cv, y_train_cv, X_val_cv, y_val_cv, X_test_cv, \"Count_Vectorizer\"\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Print out the best results for each model\n",
        "print(f\"Best KNN model for Count Vectorizer: {best_params_cv}, Validation Accuracy: {best_score_cv * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2EAinhEC0IW",
        "outputId": "813f6c6d-2d4c-45fb-e04d-1184fa26ccc3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model for Count_Vectorizer:\n",
            "Best Validation Accuracy: 89.96%\n",
            "Best Hyperparameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
            "Test predictions saved for Count_Vectorizer KNN model.\n",
            "\n",
            "Best KNN model for Count Vectorizer: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
            "Validation Accuracy: 89.96%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Run the hypertuning process for TFIDF\n",
        "best_knn_tfidf, best_score_tfidf, best_params_tfidf = tune_and_run_knn_model(\n",
        "    X_train_tfidf, y_train_tfidf, X_val_tfidf, y_val_tfidf, X_test_tfidf, \"TFIDF\"\n",
        ")\n",
        "\n",
        "\n",
        "print(f\"Best KNN model for TFIDF: {best_params_tfidf}, Validation Accuracy: {best_score_tfidf * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARgoqZug9ZGB",
        "outputId": "1889a8a9-d0fb-40fb-fb92-8240716a33a3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model for TFIDF:\n",
            "Best Validation Accuracy: 86.51%\n",
            "Best Hyperparameters: {'metric': 'euclidean', 'n_neighbors': 5, 'weights': 'distance'}\n",
            "Test predictions saved for TFIDF KNN model.\n",
            "\n",
            "Best KNN model for TFIDF: {'metric': 'euclidean', 'n_neighbors': 5, 'weights': 'distance'}\n",
            "Validation Accuracy: 86.51%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Run the hypertuning process for Word2Vec\n",
        "best_knn_w2v, best_score_w2v, best_params_w2v = tune_and_run_knn_model(\n",
        "    X_train_w2v, y_train_w2v, X_val_w2v, y_val_w2v, X_test_w2v, \"Word2Vec\"\n",
        ")\n",
        "\n",
        "print(f\"Best KNN model for Word2Vec: {best_params_w2v}, Validation Accuracy: {best_score_w2v * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "tGyTOmjG9ZM_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a54762a-a935-4542-c1a8-c0135e9162db"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model for Word2Vec:\n",
            "Best Validation Accuracy: 82.32%\n",
            "Best Hyperparameters: {'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'distance'}\n",
            "Test predictions saved for Word2Vec KNN model.\n",
            "\n",
            "Best KNN model for Word2Vec: {'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'distance'}\n",
            "Validation Accuracy: 82.32%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JCb3M6_A9ZQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGB models for 3 embeddings"
      ],
      "metadata": {
        "id": "6WLA3DRy9s_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import ParameterGrid\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from tqdm import tqdm\n",
        "import joblib\n",
        "\n",
        "# Define the hyperparameter grid for XGBoost\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.01, 0.1],\n",
        "}\n",
        "\n",
        "# Function to run hypertuning for each vectorizer and return the best XGBoost model\n",
        "def tune_and_run_xgb_model(X_train, y_train, X_val, y_val, X_test, vectorizer_name):\n",
        "    param_combinations = list(ParameterGrid(param_grid))  # Get all parameter combinations\n",
        "    best_score = 0\n",
        "    best_params = None\n",
        "    best_xgb = None\n",
        "\n",
        "    # Progress bar using tqdm to track tuning process\n",
        "    for params in tqdm(param_combinations, desc=f\"Tuning XGBoost for {vectorizer_name}\", unit=\"combination\"):\n",
        "        # Initialize XGBoost with current hyperparameters\n",
        "        xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42, **params)\n",
        "\n",
        "        # Fit the XGBoost model\n",
        "        xgb.fit(X_train, y_train)\n",
        "\n",
        "        # Make predictions on validation data\n",
        "        y_pred_val = xgb.predict(X_val)\n",
        "\n",
        "        # Evaluate the model\n",
        "        accuracy = accuracy_score(y_val, y_pred_val)\n",
        "\n",
        "        # Keep track of the best model based on validation accuracy\n",
        "        if accuracy > best_score:\n",
        "            best_score = accuracy\n",
        "            best_params = params\n",
        "            best_xgb = xgb\n",
        "\n",
        "    # Print the best results for the current vectorizer\n",
        "    print(f\"\\nBest model for {vectorizer_name}:\")\n",
        "    print(f\"Best Validation Accuracy: {best_score * 100:.2f}%\")\n",
        "    print(f\"Best Hyperparameters: {best_params}\")\n",
        "\n",
        "    # Now use the best model to predict on the test data\n",
        "    y_pred_test = best_xgb.predict(X_test)\n",
        "\n",
        "    # Save the best model's predictions for the test set\n",
        "\n",
        "    return best_xgb, best_score, best_params, y_pred_test\n"
      ],
      "metadata": {
        "id": "LXj8ReIu9mt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Run the hypertuning process for Count Vectorizer\n",
        "best_xg_cv, best_score_cv, best_params_cv, y_pred_cv = tune_and_run_xgb_model(\n",
        "    X_train_cv, y_train_cv, X_val_cv, y_val_cv, X_test_cv, \"Count_Vectorizer\"\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Print out the best results for each model\n",
        "print(f\"Best KNN model for Count Vectorizer: {best_params_cv}, Validation Accuracy: {best_score_cv * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oThkbS7OD7uc",
        "outputId": "70cec3b2-e209-4c84-845b-3343f42438f4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model for Count_Vectorizer:\n",
            "Best Validation Accuracy: 65.08%\n",
            "Best Hyperparameters: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 300}\n",
            "Best KNN model for Count Vectorizer: {{'learning_rate': {best_learning_rate_cv}, 'max_depth': {best_max_depth_cv}, 'n_estimators': {best_n_estimators_cv}}}, Validation Accuracy: {best_validation_accuracy_cv}%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Run the hypertuning process for TFIDF\n",
        "best_xg_tfidf, best_score_tfidf, best_params_tfidf, y_pred_tfidf = tune_and_run_xgb_model(\n",
        "    X_train_tfidf, y_train_tfidf, X_val_tfidf, y_val_tfidf, X_test_tfidf, \"TFIDF\"\n",
        ")\n",
        "\n",
        "\n",
        "print(f\"Best KNN model for TFIDF: {best_params_tfidf}, Validation Accuracy: {best_score_tfidf * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCYStRlUECPk",
        "outputId": "e97df861-22a2-47b4-c00f-d8b56aa95911"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model for TFIDF:\n",
            "Best Validation Accuracy: 64.14%\n",
            "Best Hyperparameters: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 300}\n",
            "Best KNN model for TFIDF: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 300}, Validation Accuracy: 64.14%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_clf = XGBClassifier(\n",
        "        learning_rate=0.1,\n",
        "        n_estimators=400,\n",
        "        max_depth=8,\n",
        "        objective='multi:softmax',\n",
        "        use_label_encoder=False,\n",
        "        eval_metric='logloss'\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "\n",
        "\n",
        "xgb_clf.fit(X_train_w2v, y_train_w2v)\n",
        "\n",
        "# Make predictions on validation and test sets\n",
        "y_val_pred = xgb_clf.predict(X_val_w2v)\n",
        "y_pred_w2v = xgb_clf.predict(X_test_w2v)\n",
        "\n",
        "# Calculate validation accuracy\n",
        "val_accuracy = accuracy_score(y_val_w2v, y_val_pred)\n",
        "# Print the validation accuracy\n",
        "print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")\n",
        "\n",
        "accuracy_cv = accuracy_score(y_test, y_pred_w2v)\n",
        "report_cv = classification_report(y_test, y_pred_w2v)\n",
        "\n",
        "print(f\"Test Accuracy for word2vec: {accuracy_cv * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvLUClxZEoO9",
        "outputId": "95d5f9d3-35f4-489e-8bf3-c6e3078f8d11"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 76.66%\n",
            "Test Accuracy for Word2Vec: 90.2%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MLP models for 3 embedingsx"
      ],
      "metadata": {
        "id": "DVqlW3g2SiKP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device('/GPU:0'):\n",
        "\n",
        "\n",
        "  # Define the model\n",
        "  model = Sequential()\n",
        "\n",
        "  # Input layer\n",
        "  model.add(Dense(1024, activation='relu', input_shape=(X_train_cv.shape[1],)))\n",
        "\n",
        "  # Hidden layer 1\n",
        "  model.add(Dense(256, activation='relu'))\n",
        "\n",
        "  # Dropout to avoid overfitting\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  # Hidden layer 2\n",
        "  model.add(Dense(64, activation='relu'))\n",
        "\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  model.add(Dense(16, activation='relu'))\n",
        "\n",
        "\n",
        "  # Output layer (Assuming multi-class classification with softmax)\n",
        "  model.add(Dense(4, activation='softmax'))\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(optimizer='adam',\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  # Train the model\n",
        "  history = model.fit(X_train_cv, y_train_cv,\n",
        "                      epochs=5,\n",
        "                      batch_size=32,\n",
        "                      validation_data=(X_val_cv, y_val_cv))\n",
        "\n",
        "  # Evaluate the model on test data\n",
        "  test_loss, test_acc = model.evaluate(X_test_cv, y_test)\n",
        "  print(f\"Test accuracy: {test_acc * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ur9VliGkYKJb",
        "outputId": "cbe70808-c190-4095-c461-4a2f346a213f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 14ms/step - accuracy: 0.5630 - loss: 1.0408 - val_accuracy: 0.8719 - val_loss: 0.3739\n",
            "Epoch 2/5\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.9333 - loss: 0.2096 - val_accuracy: 0.9205 - val_loss: 0.2586\n",
            "Epoch 3/5\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.9737 - loss: 0.0828 - val_accuracy: 0.9301 - val_loss: 0.2698\n",
            "Epoch 4/5\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.9816 - loss: 0.0573 - val_accuracy: 0.9272 - val_loss: 0.3342\n",
            "Epoch 5/5\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.9847 - loss: 0.0463 - val_accuracy: 0.9214 - val_loss: 0.3953\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9631 - loss: 0.2455\n",
            "Test accuracy: 96.50%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  # Define the model\n",
        "  model = Sequential()\n",
        "\n",
        "  # Input layer\n",
        "  model.add(Dense(1024, activation='relu', input_shape=(X_train_tfidf.shape[1],)))\n",
        "\n",
        "  # Hidden layer 1\n",
        "  model.add(Dense(256, activation='relu'))\n",
        "\n",
        "  # Dropout to avoid overfitting\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  # Hidden layer 2\n",
        "  model.add(Dense(64, activation='relu'))\n",
        "\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  model.add(Dense(16, activation='relu'))\n",
        "\n",
        "\n",
        "  # Output layer (Assuming multi-class classification with softmax)\n",
        "  model.add(Dense(4, activation='softmax'))\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(optimizer='adam',\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  # Train the model\n",
        "  history = model.fit(X_train_tfidf, y_train_tfidf,\n",
        "                      epochs=4,\n",
        "                      batch_size=32,\n",
        "                      validation_data=(X_val_tfidf, y_val_tfidf))\n",
        "\n",
        "  # Evaluate the model on test data\n",
        "  test_loss, test_acc = model.evaluate(X_test_tfidf, y_test)\n",
        "  print(f\"Test accuracy: {test_acc * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKdsijaiPaUl",
        "outputId": "ef3cd848-f29f-485a-bcbe-43eb92caa265"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 13ms/step - accuracy: 0.5639 - loss: 1.0269 - val_accuracy: 0.8755 - val_loss: 0.3518\n",
            "Epoch 2/4\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.9320 - loss: 0.2176 - val_accuracy: 0.9188 - val_loss: 0.2513\n",
            "Epoch 3/4\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.9721 - loss: 0.0845 - val_accuracy: 0.9275 - val_loss: 0.2636\n",
            "Epoch 4/4\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.9808 - loss: 0.0561 - val_accuracy: 0.9258 - val_loss: 0.3030\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9728 - loss: 0.1536\n",
            "Test accuracy: 97.30%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## here is the best score until now"
      ],
      "metadata": {
        "id": "I12ozOALCAvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "\n",
        "# Input layer\n",
        "model.add(Dense(256, activation='relu', input_shape=(X_train_w2v.shape[1],)))\n",
        "\n",
        "# Dropout to avoid overfitting\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Hidden layer 2\n",
        "model.add(Dense(64, activation='relu'))\n",
        "\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(16, activation='relu'))\n",
        "\n",
        "\n",
        "# Output layer (Assuming multi-class classification with softmax)\n",
        "model.add(Dense(4, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train_w2v, y_train_w2v,\n",
        "                    epochs=100,\n",
        "                    batch_size=32,\n",
        "                    validation_data=(X_val_w2v, y_val_w2v))\n",
        "\n",
        "# Evaluate the model on test data\n",
        "test_loss, test_acc = model.evaluate(X_test_w2v, y_test)\n",
        "print(f\"Test accuracy: {test_acc * 100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "KIXmhaZY-VkL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30e3ede3-9eb9-468e-b23e-4b51c498755b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.4413 - loss: 1.2532 - val_accuracy: 0.5064 - val_loss: 1.1458\n",
            "Epoch 2/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.4913 - loss: 1.1756 - val_accuracy: 0.5169 - val_loss: 1.1300\n",
            "Epoch 3/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.5014 - loss: 1.1640 - val_accuracy: 0.5210 - val_loss: 1.1200\n",
            "Epoch 4/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.5071 - loss: 1.1510 - val_accuracy: 0.5185 - val_loss: 1.1209\n",
            "Epoch 5/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5065 - loss: 1.1460 - val_accuracy: 0.5241 - val_loss: 1.1101\n",
            "Epoch 6/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5111 - loss: 1.1414 - val_accuracy: 0.5295 - val_loss: 1.1089\n",
            "Epoch 7/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5129 - loss: 1.1315 - val_accuracy: 0.5281 - val_loss: 1.0983\n",
            "Epoch 8/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5201 - loss: 1.1214 - val_accuracy: 0.5311 - val_loss: 1.0918\n",
            "Epoch 9/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5184 - loss: 1.1225 - val_accuracy: 0.5323 - val_loss: 1.0901\n",
            "Epoch 10/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.5181 - loss: 1.1257 - val_accuracy: 0.5296 - val_loss: 1.0902\n",
            "Epoch 11/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5220 - loss: 1.1153 - val_accuracy: 0.5351 - val_loss: 1.0876\n",
            "Epoch 12/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.5286 - loss: 1.1050 - val_accuracy: 0.5347 - val_loss: 1.0894\n",
            "Epoch 13/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.5215 - loss: 1.1121 - val_accuracy: 0.5355 - val_loss: 1.0819\n",
            "Epoch 14/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.5211 - loss: 1.1094 - val_accuracy: 0.5344 - val_loss: 1.0800\n",
            "Epoch 15/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.5220 - loss: 1.1073 - val_accuracy: 0.5352 - val_loss: 1.0805\n",
            "Epoch 16/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.5299 - loss: 1.0964 - val_accuracy: 0.5349 - val_loss: 1.0815\n",
            "Epoch 17/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.5266 - loss: 1.1053 - val_accuracy: 0.5358 - val_loss: 1.0762\n",
            "Epoch 18/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5253 - loss: 1.1021 - val_accuracy: 0.5348 - val_loss: 1.0733\n",
            "Epoch 19/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5292 - loss: 1.0968 - val_accuracy: 0.5395 - val_loss: 1.0709\n",
            "Epoch 20/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.5291 - loss: 1.0961 - val_accuracy: 0.5385 - val_loss: 1.0709\n",
            "Epoch 21/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5290 - loss: 1.0951 - val_accuracy: 0.5393 - val_loss: 1.0722\n",
            "Epoch 22/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5352 - loss: 1.0939 - val_accuracy: 0.5451 - val_loss: 1.0682\n",
            "Epoch 23/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.5301 - loss: 1.0979 - val_accuracy: 0.5396 - val_loss: 1.0684\n",
            "Epoch 24/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5367 - loss: 1.0873 - val_accuracy: 0.5456 - val_loss: 1.0701\n",
            "Epoch 25/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5322 - loss: 1.0916 - val_accuracy: 0.5428 - val_loss: 1.0676\n",
            "Epoch 26/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5330 - loss: 1.0885 - val_accuracy: 0.5428 - val_loss: 1.0662\n",
            "Epoch 27/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5396 - loss: 1.0858 - val_accuracy: 0.5436 - val_loss: 1.0652\n",
            "Epoch 28/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5330 - loss: 1.0899 - val_accuracy: 0.5449 - val_loss: 1.0624\n",
            "Epoch 29/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.5389 - loss: 1.0813 - val_accuracy: 0.5466 - val_loss: 1.0584\n",
            "Epoch 30/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.5341 - loss: 1.0869 - val_accuracy: 0.5487 - val_loss: 1.0647\n",
            "Epoch 31/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.5358 - loss: 1.0857 - val_accuracy: 0.5464 - val_loss: 1.0612\n",
            "Epoch 32/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.5363 - loss: 1.0848 - val_accuracy: 0.5495 - val_loss: 1.0580\n",
            "Epoch 33/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5387 - loss: 1.0812 - val_accuracy: 0.5474 - val_loss: 1.0620\n",
            "Epoch 34/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.5381 - loss: 1.0851 - val_accuracy: 0.5505 - val_loss: 1.0538\n",
            "Epoch 35/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.5364 - loss: 1.0818 - val_accuracy: 0.5489 - val_loss: 1.0555\n",
            "Epoch 36/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5371 - loss: 1.0807 - val_accuracy: 0.5530 - val_loss: 1.0568\n",
            "Epoch 37/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5401 - loss: 1.0785 - val_accuracy: 0.5489 - val_loss: 1.0571\n",
            "Epoch 38/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5429 - loss: 1.0755 - val_accuracy: 0.5476 - val_loss: 1.0563\n",
            "Epoch 39/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5370 - loss: 1.0794 - val_accuracy: 0.5511 - val_loss: 1.0548\n",
            "Epoch 40/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5392 - loss: 1.0826 - val_accuracy: 0.5477 - val_loss: 1.0542\n",
            "Epoch 41/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5430 - loss: 1.0775 - val_accuracy: 0.5492 - val_loss: 1.0574\n",
            "Epoch 42/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5375 - loss: 1.0806 - val_accuracy: 0.5503 - val_loss: 1.0548\n",
            "Epoch 43/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5408 - loss: 1.0780 - val_accuracy: 0.5563 - val_loss: 1.0476\n",
            "Epoch 44/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5430 - loss: 1.0734 - val_accuracy: 0.5500 - val_loss: 1.0502\n",
            "Epoch 45/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.5428 - loss: 1.0742 - val_accuracy: 0.5513 - val_loss: 1.0515\n",
            "Epoch 46/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.5402 - loss: 1.0799 - val_accuracy: 0.5525 - val_loss: 1.0451\n",
            "Epoch 47/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5402 - loss: 1.0730 - val_accuracy: 0.5546 - val_loss: 1.0510\n",
            "Epoch 48/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5450 - loss: 1.0693 - val_accuracy: 0.5521 - val_loss: 1.0484\n",
            "Epoch 49/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5433 - loss: 1.0709 - val_accuracy: 0.5542 - val_loss: 1.0502\n",
            "Epoch 50/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5400 - loss: 1.0738 - val_accuracy: 0.5521 - val_loss: 1.0469\n",
            "Epoch 51/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5463 - loss: 1.0650 - val_accuracy: 0.5547 - val_loss: 1.0447\n",
            "Epoch 52/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.5434 - loss: 1.0652 - val_accuracy: 0.5558 - val_loss: 1.0457\n",
            "Epoch 53/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.5427 - loss: 1.0699 - val_accuracy: 0.5541 - val_loss: 1.0460\n",
            "Epoch 54/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.5476 - loss: 1.0677 - val_accuracy: 0.5552 - val_loss: 1.0420\n",
            "Epoch 55/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.5440 - loss: 1.0636 - val_accuracy: 0.5527 - val_loss: 1.0470\n",
            "Epoch 56/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5495 - loss: 1.0645 - val_accuracy: 0.5581 - val_loss: 1.0433\n",
            "Epoch 57/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.5446 - loss: 1.0650 - val_accuracy: 0.5555 - val_loss: 1.0448\n",
            "Epoch 58/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.5421 - loss: 1.0717 - val_accuracy: 0.5615 - val_loss: 1.0414\n",
            "Epoch 59/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.5467 - loss: 1.0659 - val_accuracy: 0.5582 - val_loss: 1.0417\n",
            "Epoch 60/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.5444 - loss: 1.0666 - val_accuracy: 0.5553 - val_loss: 1.0382\n",
            "Epoch 61/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5491 - loss: 1.0638 - val_accuracy: 0.5530 - val_loss: 1.0402\n",
            "Epoch 62/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.5454 - loss: 1.0641 - val_accuracy: 0.5572 - val_loss: 1.0393\n",
            "Epoch 63/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.5486 - loss: 1.0653 - val_accuracy: 0.5546 - val_loss: 1.0421\n",
            "Epoch 64/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.5410 - loss: 1.0667 - val_accuracy: 0.5578 - val_loss: 1.0374\n",
            "Epoch 65/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.5487 - loss: 1.0595 - val_accuracy: 0.5577 - val_loss: 1.0410\n",
            "Epoch 66/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.5447 - loss: 1.0675 - val_accuracy: 0.5565 - val_loss: 1.0356\n",
            "Epoch 67/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.5489 - loss: 1.0632 - val_accuracy: 0.5577 - val_loss: 1.0372\n",
            "Epoch 68/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5478 - loss: 1.0642 - val_accuracy: 0.5568 - val_loss: 1.0364\n",
            "Epoch 69/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.5497 - loss: 1.0586 - val_accuracy: 0.5531 - val_loss: 1.0462\n",
            "Epoch 70/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.5482 - loss: 1.0637 - val_accuracy: 0.5559 - val_loss: 1.0387\n",
            "Epoch 71/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.5479 - loss: 1.0565 - val_accuracy: 0.5590 - val_loss: 1.0381\n",
            "Epoch 72/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.5474 - loss: 1.0642 - val_accuracy: 0.5548 - val_loss: 1.0370\n",
            "Epoch 73/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5486 - loss: 1.0616 - val_accuracy: 0.5591 - val_loss: 1.0339\n",
            "Epoch 74/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5467 - loss: 1.0605 - val_accuracy: 0.5597 - val_loss: 1.0346\n",
            "Epoch 75/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.5499 - loss: 1.0597 - val_accuracy: 0.5572 - val_loss: 1.0352\n",
            "Epoch 76/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5476 - loss: 1.0608 - val_accuracy: 0.5575 - val_loss: 1.0336\n",
            "Epoch 77/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5459 - loss: 1.0639 - val_accuracy: 0.5569 - val_loss: 1.0342\n",
            "Epoch 78/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.5522 - loss: 1.0551 - val_accuracy: 0.5583 - val_loss: 1.0354\n",
            "Epoch 79/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.5471 - loss: 1.0623 - val_accuracy: 0.5625 - val_loss: 1.0308\n",
            "Epoch 80/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5499 - loss: 1.0590 - val_accuracy: 0.5627 - val_loss: 1.0327\n",
            "Epoch 81/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5510 - loss: 1.0566 - val_accuracy: 0.5586 - val_loss: 1.0314\n",
            "Epoch 82/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5486 - loss: 1.0586 - val_accuracy: 0.5621 - val_loss: 1.0298\n",
            "Epoch 83/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.5552 - loss: 1.0555 - val_accuracy: 0.5585 - val_loss: 1.0301\n",
            "Epoch 84/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.5516 - loss: 1.0582 - val_accuracy: 0.5571 - val_loss: 1.0371\n",
            "Epoch 85/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.5496 - loss: 1.0558 - val_accuracy: 0.5608 - val_loss: 1.0311\n",
            "Epoch 86/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.5472 - loss: 1.0606 - val_accuracy: 0.5604 - val_loss: 1.0347\n",
            "Epoch 87/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5530 - loss: 1.0524 - val_accuracy: 0.5600 - val_loss: 1.0299\n",
            "Epoch 88/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.5547 - loss: 1.0508 - val_accuracy: 0.5624 - val_loss: 1.0265\n",
            "Epoch 89/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5500 - loss: 1.0558 - val_accuracy: 0.5562 - val_loss: 1.0327\n",
            "Epoch 90/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.5562 - loss: 1.0519 - val_accuracy: 0.5637 - val_loss: 1.0288\n",
            "Epoch 91/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5514 - loss: 1.0537 - val_accuracy: 0.5631 - val_loss: 1.0296\n",
            "Epoch 92/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5526 - loss: 1.0512 - val_accuracy: 0.5570 - val_loss: 1.0334\n",
            "Epoch 93/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.5533 - loss: 1.0507 - val_accuracy: 0.5616 - val_loss: 1.0269\n",
            "Epoch 94/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.5519 - loss: 1.0539 - val_accuracy: 0.5621 - val_loss: 1.0279\n",
            "Epoch 95/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.5545 - loss: 1.0484 - val_accuracy: 0.5577 - val_loss: 1.0295\n",
            "Epoch 96/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5532 - loss: 1.0529 - val_accuracy: 0.5599 - val_loss: 1.0333\n",
            "Epoch 97/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5576 - loss: 1.0481 - val_accuracy: 0.5654 - val_loss: 1.0270\n",
            "Epoch 98/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5569 - loss: 1.0512 - val_accuracy: 0.5623 - val_loss: 1.0282\n",
            "Epoch 99/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.5542 - loss: 1.0487 - val_accuracy: 0.5637 - val_loss: 1.0300\n",
            "Epoch 100/100\n",
            "\u001b[1m1738/1738\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.5556 - loss: 1.0507 - val_accuracy: 0.5596 - val_loss: 1.0259\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5907 - loss: 0.9731 \n",
            "Test accuracy: 57.80%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# here is the best score until now\n",
        "## tfidf with Multi-Perceptron Neural Network with accuracy 97.40"
      ],
      "metadata": {
        "id": "A9oWEjPXCFZA"
      }
    }
  ]
}